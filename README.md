# ğŸ¤– RAG_MCP_CODE_SEARCH

**RAG_MCP_CODE_SEARCH** is an intelligent **AI-driven code retrieval and modification system** that combines the power of **RAG (Retrieval-Augmented Generation)** with **MCP (Modular Code Processing)**. It enables seamless **code search, draft generation, and automatic synchronization** between your **local workspace** and **Vector Database**.

---

## ğŸ§  Overview

This system provides an end-to-end solution for intelligent code management:

- ğŸ“¦ **Upload and index** zipped code projects into a Vector Database (one-time setup)
- ğŸ” **Query relevant code snippets** using natural language powered by RAG
- âœï¸ **Generate code modifications** automatically via the MCP toolchain
- âœ… **Review and approve** changes before applying them to your local folder and Vector DB
- âš™ï¸ **FastAPI + Streamlit architecture** for robust backend-frontend integration

ğŸ¥ **Demo Video:** [Watch on Loom](https://www.loom.com/share/492fe76b6c9c410f921f5fdae06d4bfa)

---

## âœ¨ Key Features

- ğŸ”— **RAG + MCP Integration**: Context-aware intelligent code management
- ğŸ§  **Semantic Search**: Powered by Vector Database (Zilliz) for accurate code retrieval
- ğŸ’¬ **Natural Language Interface**: Query your codebase using plain English
- ğŸ§¾ **Draft-Before-Apply**: Review generated modifications before committing changes
- ğŸ”„ **Automatic Synchronization**: Keep your local folder and Vector DB in perfect sync
- âš™ï¸ **Modular Architecture**: Extensible and production-ready design
- ğŸš€ **Fast Processing**: Efficient indexing and retrieval mechanisms

---

## ğŸ—ï¸ Project Structure

```
RAG_MCP_CODE_SEARCH/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ uploads/           # Folder for uploaded code zips & extracted files
â”‚   â”œâ”€â”€ files.py           # File handling utilities
â”‚   â””â”€â”€ uploads.py         # Upload processing logic
â”‚
â”œâ”€â”€ server.py              # FastAPI backend (API endpoints, VectorDB handling)
â”œâ”€â”€ streamlit.py           # Streamlit frontend for user interaction
â”œâ”€â”€ requirements.txt       # Project dependencies
â”œâ”€â”€ .env                   # Environment variables (see configuration below)
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸ” Environment Configuration

Create a `.env` file in the root directory with the following configuration:

```bash
# OpenAI API Configuration
OPENAI_API_KEY="your-openai-api-key"

# Zilliz Cloud Configuration
CLUSTER_ENDPOINT="your-zilliz-cluster-endpoint"
TOKEN="your-zilliz-token"
COLLECTION_NAME="CodeBase"

# Anthropic API Configuration
ANTHROPIC_API_KEY="your-anthropic-api-key"

# Folder Paths
FOLDER_TO_UPDATE="path/to/your/project/folder"
FOLDER_TO_UPLOAD="src/uploads"
```

### Configuration Parameters

| Parameter | Description |
|-----------|-------------|
| `OPENAI_API_KEY` | Your OpenAI API key for embeddings and LLM operations |
| `CLUSTER_ENDPOINT` | Zilliz Cloud cluster endpoint URL |
| `TOKEN` | Authentication token for Zilliz Cloud |
| `COLLECTION_NAME` | Name of the collection in Zilliz (default: "CodeBase") |
| `ANTHROPIC_API_KEY` | Your Anthropic API key for Claude integration |
| `FOLDER_TO_UPDATE` | Local folder path where code updates will be applied |
| `FOLDER_TO_UPLOAD` | Folder for storing uploaded ZIP files and extracted code |

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/RAG_MCP_CODE_SEARCH.git
cd RAG_MCP_CODE_SEARCH
```

### 2ï¸âƒ£ Create and Activate Virtual Environment

**Linux/macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the root directory and add your API keys and configuration as shown in the [Environment Configuration](#-environment-configuration) section above.

---

## â–¶ï¸ Running the Project

### Step 1: Start the FastAPI Server

```bash
uvicorn server:app --reload
```

The API server will be available at `http://localhost:8000`

### Step 2: Launch the Streamlit Interface

Open a new terminal window and run:

```bash
streamlit run streamlit.py
```

The Streamlit UI will open automatically in your default browser at `http://localhost:8501`

---

## ğŸ’¡ How It Works

### Workflow Overview

1. **ğŸ“¤ Upload**: Upload a ZIP folder containing your project source files through the Streamlit interface

2. **âš¡ Index**: The system extracts and indexes your code into the Vector Database
   - *Note: This process takes some time but only needs to be done once per project*

3. **ğŸ” Query**: Once indexing is complete, query your codebase using natural language
   - Example: *"Find all authentication functions"* or *"Show me database connection code"*

4. **âœï¸ Generate**: The MCP-based tool fetches relevant code snippets and generates draft modifications automatically

5. **ğŸ‘€ Review**: Examine the proposed changes in the draft view

6. **âœ… Apply**: After approval, the code is updated in both your local folder and the Vector Database seamlessly

### Architecture Flow

```
User Query â†’ Streamlit UI â†’ FastAPI Backend â†’ RAG Pipeline â†’ Vector DB
                                              â†“
                                         Code Retrieval
                                              â†“
                                         MCP Processing
                                              â†“
                                    Draft Code Generation
                                              â†“
                                    User Review & Approval
                                              â†“
                              Local Folder Update + Vector DB Sync
```

---

## ğŸ§  Tech Stack

| Component | Technology |
|-----------|-----------|
| **Frontend** | Streamlit |
| **Backend** | FastAPI |
| **Vector Store** | Zilliz Cloud |
| **Model APIs** | OpenAI, Anthropic |
| **Language Model** | RAG pipeline |
| **Integration** | MCP (Modular Code Processing) |
| **Deployment** | Uvicorn |

---

## ğŸ“‹ Requirements

- Python 3.8+
- OpenAI API access
- Anthropic API access
- Zilliz Cloud account
- Sufficient storage for code indexing

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ› Troubleshooting

### Common Issues

**Issue**: Vector DB connection failed
- **Solution**: Verify your `CLUSTER_ENDPOINT` and `TOKEN` in the `.env` file

**Issue**: Indexing takes too long
- **Solution**: This is normal for large codebases. The indexing only needs to be done once.

**Issue**: API rate limits exceeded
- **Solution**: Check your OpenAI/Anthropic API usage limits and upgrade if necessary

---

## ğŸ“ Support

For questions and support, please open an issue on GitHub or contact the maintainers.

---

**Built with â¤ï¸ using RAG and MCP technologies**
